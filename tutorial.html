

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Quick tutorial &mdash; skl-groups 0.1.0-dev documentation</title>
  

  
  

  
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  
    <link rel="top" title="skl-groups 0.1.0-dev documentation" href="index.html"/>
        <link rel="next" title="API reference" href="reference.html"/>
        <link rel="prev" title="Installation" href="installation.html"/> 

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.6.2/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-nav-search">
        <a href="index.html" class="fa fa-home"> skl-groups</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        
        
            <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="who.html">Who this package is for</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="installation.html#release-versions">Release versions</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#development-version">Development version</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#flann">FLANN</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#accelerated-version">Accelerated version</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="">Quick tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#motivation">Motivation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#feature-representation">Feature representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#means">Means</a></li>
<li class="toctree-l2"><a class="reference internal" href="#bag-of-words">Bag of Words</a></li>
<li class="toctree-l2"><a class="reference internal" href="#divergences">Divergences</a></li>
<li class="toctree-l2"><a class="reference internal" href="#l2-density-transformer">L2 density transformer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="reference.html">API reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="reference.html#features-representation">Features representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="reference.html#preprocessing">Preprocessing</a></li>
<li class="toctree-l2"><a class="reference internal" href="reference.html#summaries">Summaries</a></li>
<li class="toctree-l2"><a class="reference internal" href="reference.html#divergences">Divergences</a></li>
<li class="toctree-l2"><a class="reference internal" href="reference.html#kernel-utilities">Kernel utilities</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="todo.html">Planned improvements</a></li>
</ul>

        
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">skl-groups</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
      
    <li>Quick tutorial</li>
      <li class="wy-breadcrumbs-aside">
        
          <a href="_sources/tutorial.txt" rel="nofollow"> View page source</a>
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            
  <div class="section" id="quick-tutorial">
<h1>Quick tutorial<a class="headerlink" href="#quick-tutorial" title="Permalink to this headline">¶</a></h1>
<div class="section" id="motivation">
<h2>Motivation<a class="headerlink" href="#motivation" title="Permalink to this headline">¶</a></h2>
<p>Let&#8217;s say we have a bunch of labeled data.
Given a new set of data, we want to be able to predict its label.
This is the standard machine learning problem setting of
classification (if the labels are distinct classes)
or regression (if the labels are continuous values).</p>
<p>Most algorithms to solve these problems operate by
extracting feature vectors from the underlying data,
and then finding regions in feature space that correspond to the classes,
or smooth-ish functions in that space that match the regression problem.</p>
<p>For example, if you&#8217;re classifying emails as spam or not spam,
you might choose one feature dimension that
corresponds to the number of times that the word &#8220;account&#8221; is used,
another for the number of times &#8220;pharmacy&#8221; appears,
another for whether the sender is in your address book,
and so on.</p>
<p>These choices are very important:
even the fanciest learning algorithm can&#8217;t do anything with the wrong features,
and even the simplest can often do very well with the right ones.</p>
<p>But sometime it&#8217;s not easy to summarize your data in a single, fixed-length vector.
One particular case where it&#8217;s difficult: if your data is really comprised of a set of points.</p>
<p>For example, consider the following data,
where the &#8216;+&#8217; and &#8216;-&#8216; indicate training labels
and the &#8216;?&#8217; is a test point:</p>
<p>(<a class="reference external" href=".//tutorial-1.py">Source code</a>, <a class="reference external" href=".//tutorial-1.png">png</a>, <a class="reference external" href=".//tutorial-1.hires.png">hires.png</a>, <a class="reference external" href=".//tutorial-1.pdf">pdf</a>)</p>
<div class="figure">
<img alt="_images/tutorial-1.png" src="_images/tutorial-1.png" />
</div>
<p>The test set obviously belongs to the &#8220;-&#8221; class.
How can we get that answer with machine learning?</p>
</div>
<div class="section" id="feature-representation">
<h2>Feature representation<a class="headerlink" href="#feature-representation" title="Permalink to this headline">¶</a></h2>
<p>First, how do we even represent the data?</p>
<p>In scikit-learn, where objects are represented by feature vectors,
most learning methods take in a 2d array
(<a class="reference external" href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.8)"><tt class="xref py py-class docutils literal"><span class="pre">numpy.ndarray</span></tt></a> or sometimes <a class="reference external" href="http://docs.scipy.org/doc/scipy/reference/sparse.html#module-scipy.sparse" title="(in SciPy v0.14.0)"><tt class="xref py py-mod docutils literal"><span class="pre">scipy.sparse</span></tt></a>)
of shape <tt class="docutils literal"><span class="pre">(n,</span> <span class="pre">n_features)</span></tt>
where each of the <tt class="docutils literal"><span class="pre">n</span></tt> rows represents a different vector.</p>
<p>In skl-groups, each object is instead a set of vectors.
We represent that as a Python <a class="reference external" href="http://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.4)"><tt class="xref py py-class docutils literal"><span class="pre">list</span></tt></a> of arrays,
where each array is of shape <tt class="docutils literal"><span class="pre">(n_pts[i],</span> <span class="pre">n_features)</span></tt>.
The feature dimensionality must be consistent between different sets,
but the number of points in each set can vary (as it does above).
(This is why we use a list; numpy arrays don&#8217;t support &#8220;ragged&#8221; arrays like this.)</p>
<p>Internally, most methods convert these lists into
<a class="reference internal" href="skl_groups/skl_groups.features.Features.html#skl_groups.features.Features" title="skl_groups.features.Features"><tt class="xref py py-class docutils literal"><span class="pre">features.Features</span></tt></a> objects,
which provide a convenient way to access the data consistently,
and can optionally store any metadata you like along with each bag.</p>
<p>For example, here&#8217;s how we made the data for the plot above:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="n">mvn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">87</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">3</span>

<span class="k">def</span> <span class="nf">nudge</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
    <span class="n">nudge</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">nudge</span><span class="p">[:</span><span class="n">k</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-.</span><span class="mi">5</span>
    <span class="n">nudge</span><span class="p">[</span><span class="n">k</span><span class="o">//</span><span class="mi">2</span><span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">.</span><span class="mi">5</span>
    <span class="k">return</span> <span class="n">nudge</span>
<span class="n">plus</span> <span class="o">=</span> <span class="p">[</span><span class="n">mvn</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[[</span><span class="o">.</span><span class="mi">1</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="o">.</span><span class="mi">35</span><span class="o">**</span><span class="mi">2</span><span class="p">]],</span> <span class="n">size</span><span class="o">=</span><span class="n">k</span><span class="p">)</span> <span class="o">+</span> <span class="n">nudge</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)]</span>

<span class="n">minus</span> <span class="o">=</span> <span class="p">[</span><span class="n">mvn</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[[</span><span class="o">.</span><span class="mi">2</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="o">.</span><span class="mi">2</span><span class="o">**</span><span class="mi">2</span><span class="p">]],</span> <span class="n">size</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)]</span>

<span class="n">test_pt</span> <span class="o">=</span> <span class="n">mvn</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[[</span><span class="o">.</span><span class="mi">2</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="o">.</span><span class="mi">2</span><span class="o">**</span><span class="mi">2</span><span class="p">]],</span> <span class="n">size</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>

<span class="n">bags</span> <span class="o">=</span> <span class="n">plus</span> <span class="o">+</span> <span class="n">minus</span> <span class="o">+</span> <span class="p">[</span><span class="n">test_pt</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">),</span> <span class="bp">False</span><span class="p">]</span>
</pre></div>
</div>
<p>We can then pass <tt class="docutils literal"><span class="pre">bags</span></tt> to skl-groups&#8217;s learning methods.
Alternatively, we can make a <a class="reference internal" href="skl_groups/skl_groups.features.Features.html#skl_groups.features.Features" title="skl_groups.features.Features"><tt class="xref py py-class docutils literal"><span class="pre">features.Features</span></tt></a> object:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skl_groups.features</span> <span class="kn">import</span> <span class="n">Features</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feats</span> <span class="o">=</span> <span class="n">Features</span><span class="p">(</span><span class="n">bags</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feats</span>
<span class="go">&lt;Features: 7 bags with 11 to 14 2-dimensional points (88 total)&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feats</span><span class="o">.</span><span class="n">labels</span>
<span class="go">array([ True,  True,  True, False, False, False, False], dtype=bool)</span>
</pre></div>
</div>
<p>By passing <tt class="docutils literal"><span class="pre">labels</span></tt>, now if we slice <tt class="docutils literal"><span class="pre">features</span></tt>,
<tt class="docutils literal"><span class="pre">labels</span></tt> will be kept track of too:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">feats</span><span class="p">[:</span><span class="mi">4</span><span class="p">]</span>
<span class="go">&lt;Features: 4 bags with 11 to 14 2-dimensional points (50 total)&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feats</span><span class="p">[:</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">labels</span>
<span class="go">array([ True,  True,  True, False], dtype=bool)</span>
</pre></div>
</div>
<p>It&#8217;s just a convenience, though; learning methods won&#8217;t use it to &#8220;cheat.&#8221;</p>
</div>
<div class="section" id="means">
<h2>Means<a class="headerlink" href="#means" title="Permalink to this headline">¶</a></h2>
<p>Perhaps the most obvious way to summarize a set of vectors is their mean,
which we can get with <a class="reference internal" href="skl_groups/skl_groups.summaries.BagMean.html#skl_groups.summaries.BagMean" title="skl_groups.summaries.BagMean"><tt class="xref py py-class docutils literal"><span class="pre">summaries.BagMean</span></tt></a>.
BagMean will turn a list of features into a single array,
which we can then plug into our favorite <a class="reference external" href="http://scikit-learn.org/stable/supervised_learning.html#supervised-learning" title="(in scikit-learn v0.14)"><em class="xref std std-ref">sklearn classifier</em></a> (or regressor, clusterer, whatever):</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skl_groups.summaries</span> <span class="kn">import</span> <span class="n">BagMean</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">BagMean</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">feats</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="go">array([[-0.02,  0.02],</span>
<span class="go">       [-0.02,  0.04],</span>
<span class="go">       [ 0.01,  0.02],</span>
<span class="go">       [ 0.04,  0.05],</span>
<span class="go">       [ 0.11,  0.07],</span>
<span class="go">       [-0.01,  0.02],</span>
<span class="go">       [ 0.02, -0.02]])</span>
</pre></div>
</div>
<div class="admonition-todo admonition" id="index-0">
<p class="first admonition-title">Todo</p>
<p class="last">Make this &#8220;live&#8221; like the plots are</p>
</div>
<p>Plotting the results:</p>
<p>(<a class="reference external" href=".//tutorial-2.py">Source code</a>, <a class="reference external" href=".//tutorial-2.png">png</a>, <a class="reference external" href=".//tutorial-2.hires.png">hires.png</a>, <a class="reference external" href=".//tutorial-2.pdf">pdf</a>)</p>
<div class="figure">
<img alt="_images/tutorial-2.png" src="_images/tutorial-2.png" />
</div>
<p>In our toy example,
the mean isn&#8217;t really enough to distinguish between the two classes.
(In fact, if you look at the distributions the points are drawn from,
all of them have expectation (0, 0).)</p>
<p>In this particular case,
the covariance matrix &#8220;flattened&#8221; into a vector would probably be good enough.
That&#8217;s not generally useful enough to have an implementation in skl_groups,
but it&#8217;d be easy enough to implement yourself by tweaking the source of BagMean.</p>
</div>
<div class="section" id="bag-of-words">
<h2>Bag of Words<a class="headerlink" href="#bag-of-words" title="Permalink to this headline">¶</a></h2>
<p>Maybe the next-most-popular way to summarize a set of features is through
&#8220;bag of words.&#8221;</p>
<p>In natural language processing,
a common way to get a basic understanding of document is to simply
take the counts of each word used in a document, and stack those into a vector
(see <a class="reference external" href="http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction" title="(in scikit-learn v0.14)"><em class="xref std std-ref">the sklearn docs</em></a>).
Computer vision researchers perform an analogous process with arbitrary feature vectors:
&#8220;quantize&#8221; the inputs into a set of <em>codewords</em>,
i.e. points where you can reasonably replace each of the input vectors with a
codeword without losing too much information,
and then represent each set by the count of each codeword.</p>
<p>We can perform this in skl_groups with the <a class="reference internal" href="skl_groups/skl_groups.summaries.BagOfWords.html#skl_groups.summaries.BagOfWords" title="skl_groups.summaries.BagOfWords"><tt class="xref py py-class docutils literal"><span class="pre">summaries.BagOfWords</span></tt></a> estimator,
which relies on k-means <a class="reference external" href="http://scikit-learn.org/stable/modules/clustering.html#clustering" title="(in scikit-learn v0.14)"><em class="xref std std-ref">clustering</em></a> to choose the codewords.
Here we use <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans" title="(in scikit-learn v0.14)"><tt class="xref py py-class docutils literal"><span class="pre">sklearn.cluster.KMeans</span></tt></a> to do it:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skl_groups.summaries</span> <span class="kn">import</span> <span class="n">BagOfWords</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bow</span> <span class="o">=</span> <span class="n">BagOfWords</span><span class="p">(</span><span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bowized</span> <span class="o">=</span> <span class="n">bow</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">feats</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bowized</span>
<span class="go">array([[0, 3, 4, 2, 0, 5],</span>
<span class="go">       [1, 4, 2, 3, 0, 3],</span>
<span class="go">       [0, 3, 2, 2, 0, 4],</span>
<span class="go">       [4, 0, 1, 0, 6, 1],</span>
<span class="go">       [4, 0, 1, 1, 4, 2],</span>
<span class="go">       [6, 0, 3, 0, 4, 1],</span>
<span class="go">       [9, 0, 0, 0, 2, 1]], dtype=int32)</span>
</pre></div>
</div>
<p>Plotting how the bags lie on the selected codewords
(codewords in red, the areas that map to them in pastel):</p>
<p>(<a class="reference external" href=".//tutorial-3.py">Source code</a>, <a class="reference external" href=".//tutorial-3.png">png</a>, <a class="reference external" href=".//tutorial-3.hires.png">hires.png</a>, <a class="reference external" href=".//tutorial-3.pdf">pdf</a>)</p>
<div class="figure">
<img alt="_images/tutorial-3.png" src="_images/tutorial-3.png" />
</div>
<p>These are much easier to distinguish
(the negatives mostly lie in the central two codewords, the positives mostly outside).
And we can solve our prediction problem:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">SVC</span><span class="p">(</span><span class="n">probability</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">bowized</span><span class="p">[:</span><span class="mi">6</span><span class="p">],</span> <span class="n">labels</span><span class="p">[:</span><span class="mi">6</span><span class="p">])</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">bowized</span><span class="p">[</span><span class="mi">6</span><span class="p">:])</span>
<span class="go">array([False], dtype=bool)</span>
</pre></div>
</div>
<p>The transformed features are six-dimensional, so we can&#8217;t just plot them directly.
But we can plot a low-dimensional embedding where distances between the points
approximately correspond to distances in the high-dimensional space with
<a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.manifold.LocallyLinearEmbedding.html#sklearn.manifold.LocallyLinearEmbedding" title="(in scikit-learn v0.14)"><tt class="xref py py-class docutils literal"><span class="pre">sklearn.manifold.LocallyLinearEmbedding</span></tt></a>:</p>
<p>(<a class="reference external" href=".//tutorial-4.py">Source code</a>, <a class="reference external" href=".//tutorial-4.png">png</a>, <a class="reference external" href=".//tutorial-4.hires.png">hires.png</a>, <a class="reference external" href=".//tutorial-4.pdf">pdf</a>)</p>
<div class="figure">
<img alt="_images/tutorial-4.png" src="_images/tutorial-4.png" />
</div>
</div>
<div class="section" id="divergences">
<h2>Divergences<a class="headerlink" href="#divergences" title="Permalink to this headline">¶</a></h2>
<p>There&#8217;s a wide class of machine learning algorithms which can run based only
on a particular kind of similarity function between objects,
known as <a class="reference external" href="https://en.wikipedia.org/wiki/Kernel_method">kernel methods</a>.
The best-known of these is the support vector machine (<a class="reference external" href="http://scikit-learn.org/stable/modules/svm.html#svm" title="(in scikit-learn v0.14)"><em class="xref std std-ref">SVM</em></a>),
but there are many others as well.
So, if we can come up with a <em>kernel</em> between sets,
we can run our SVMs or other kernel methods directly on the input sets.</p>
<p>One way to do that goes like this:
Suppose that the sets we&#8217;re given are <a class="reference external" href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables">independent and identically distributed (iid)</a>
samples from some unknown probability distribution.
Then, we can use these samples to statistically estimate a &#8220;distance&#8221; between those underlying probability distributions.
Some of the options for these distances are:</p>
<ul class="simple">
<li>the <a class="reference external" href="https://en.wikipedia.org/wiki/KL_divergence">Kullback–Leibler (KL) divergence</a></li>
<li>the <a class="reference external" href="https://en.wikipedia.org/wiki/Renyi_divergence#R.C3.A9nyi_divergence">Rényi  divergence</a></li>
<li>the <span class="math">\(L_2\)</span> distance: <span class="math">\(\int (p(x) - q(x))^2 dx\)</span> where <span class="math">\(p\)</span> and <span class="math">\(q\)</span> are the probability densities</li>
<li>the <a class="reference external" href="https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence">Jensen–Shannon divergence</a></li>
<li>the <a class="reference external" href="https://en.wikipedia.org/wiki/Hellinger_distance">Hellinger distance</a></li>
</ul>
<p>We can estimate all of these distances with
<a class="reference internal" href="skl_groups/skl_groups.divergences.KNNDivergenceEstimator.html#skl_groups.divergences.KNNDivergenceEstimator" title="skl_groups.divergences.KNNDivergenceEstimator"><tt class="xref py py-class docutils literal"><span class="pre">divergences.KNNDivergenceEstimator</span></tt></a>.
To turn these distances into a kernel,
we can put it in a <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="(in scikit-learn v0.14)"><tt class="xref py py-class docutils literal"><span class="pre">sklearn.pipeline.Pipeline</span></tt></a> with
<a class="reference internal" href="skl_groups/skl_groups.kernels.PairwisePicker.html#skl_groups.kernels.PairwisePicker" title="skl_groups.kernels.PairwisePicker"><tt class="xref py py-class docutils literal"><span class="pre">kernels.PairwisePicker</span></tt></a>,
<a class="reference internal" href="skl_groups/skl_groups.kernels.Symmetrize.html#skl_groups.kernels.Symmetrize" title="skl_groups.kernels.Symmetrize"><tt class="xref py py-class docutils literal"><span class="pre">kernels.Symmetrize</span></tt></a>,
<a class="reference internal" href="skl_groups/skl_groups.kernels.RBFize.html#skl_groups.kernels.RBFize" title="skl_groups.kernels.RBFize"><tt class="xref py py-class docutils literal"><span class="pre">kernels.RBFize</span></tt></a>,
<a class="reference internal" href="skl_groups/skl_groups.kernels.ProjectPSD.html#skl_groups.kernels.ProjectPSD" title="skl_groups.kernels.ProjectPSD"><tt class="xref py py-class docutils literal"><span class="pre">kernels.ProjectPSD</span></tt></a>
and then put it in an SVM:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skl_groups.divergences</span> <span class="kn">import</span> <span class="n">KNNDivergenceEstimator</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skl_groups.kernels</span> <span class="kn">import</span> <span class="n">PairwisePicker</span><span class="p">,</span> <span class="n">Symmetrize</span><span class="p">,</span> <span class="n">RBFize</span><span class="p">,</span> <span class="n">ProjectPSD</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
<span class="go">    (&#39;divs&#39;, KNNDivergenceEstimator(div_funcs=[&#39;kl&#39;], Ks=[2])),</span>
<span class="go">    (&#39;pick&#39;, PairwisePicker((0, 0))),</span>
<span class="go">    (&#39;symmetrize&#39;, Symmetrize()),</span>
<span class="go">    (&#39;rbf&#39;, RBFize(gamma=1, scale_by_median=True)),</span>
<span class="go">    (&#39;project&#39;, ProjectPSD()),</span>
<span class="go">    (&#39;svm&#39;, SVC(C=1, kernel=&#39;precomputed&#39;, probability=True)),</span>
<span class="go">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">feats</span><span class="p">[:</span><span class="mi">6</span><span class="p">],</span> <span class="n">labels</span><span class="p">[:</span><span class="mi">6</span><span class="p">])</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">feats</span><span class="p">[</span><span class="mi">6</span><span class="p">:])</span>
<span class="go">array([False], dtype=bool)</span>
</pre></div>
</div>
<p>In practice, you definitely want to try tuning the various parameters
with <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html#sklearn.grid_search.GridSearchCV" title="(in scikit-learn v0.14)"><tt class="xref py py-class docutils literal"><span class="pre">sklearn.grid_search.GridSearchCV</span></tt></a> or similar.
<a class="reference internal" href="skl_groups/skl_groups.kernels.RBFize.html#skl_groups.kernels.RBFize" title="skl_groups.kernels.RBFize"><tt class="xref py py-class docutils literal"><span class="pre">kernels.RBFize</span></tt></a>&#8216;s <tt class="docutils literal"><span class="pre">gamma</span></tt> and <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="(in scikit-learn v0.14)"><tt class="xref py py-class docutils literal"><span class="pre">sklearn.svm.SVC</span></tt></a>&#8216;s <tt class="docutils literal"><span class="pre">C</span></tt> need it for sure,
probably also the <tt class="docutils literal"><span class="pre">Ks</span></tt> and <tt class="docutils literal"><span class="pre">div_funcs</span></tt> in <a class="reference internal" href="skl_groups/skl_groups.divergences.KNNDivergenceEstimator.html#skl_groups.divergences.KNNDivergenceEstimator" title="skl_groups.divergences.KNNDivergenceEstimator"><tt class="xref py py-class docutils literal"><span class="pre">divergences.KNNDivergenceEstimator</span></tt></a>)
(possibly by passing lists there and tuning over different indices
in <a class="reference internal" href="skl_groups/skl_groups.kernels.PairwisePicker.html#skl_groups.kernels.PairwisePicker" title="skl_groups.kernels.PairwisePicker"><tt class="xref py py-class docutils literal"><span class="pre">kernels.PairwisePicker</span></tt></a>).
Making this process more efficient and less work for the user is
<a class="reference external" href="https://github.com/dougalsutherland/skl-groups/issues/15">high on the todo list</a>.</p>
<p>Here&#8217;s what the divergence matrix looks like for our example data:</p>
<p>(<a class="reference external" href=".//tutorial-5.py">Source code</a>, <a class="reference external" href=".//tutorial-5.png">png</a>, <a class="reference external" href=".//tutorial-5.hires.png">hires.png</a>, <a class="reference external" href=".//tutorial-5.pdf">pdf</a>)</p>
<div class="figure">
<img alt="_images/tutorial-5.png" src="_images/tutorial-5.png" />
</div>
<p>You can see that the distances are pretty low
among the block of the first three positives
and the block of the next four negatives,
and fairly high between the two blocks.
Here&#8217;s a low-dimensional version of the space that the SVM sees:</p>
<p>(<a class="reference external" href=".//tutorial-6.py">Source code</a>, <a class="reference external" href=".//tutorial-6.png">png</a>, <a class="reference external" href=".//tutorial-6.hires.png">hires.png</a>, <a class="reference external" href=".//tutorial-6.pdf">pdf</a>)</p>
<div class="figure">
<img alt="_images/tutorial-6.png" src="_images/tutorial-6.png" />
</div>
</div>
<div class="section" id="l2-density-transformer">
<h2>L2 density transformer<a class="headerlink" href="#l2-density-transformer" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="skl_groups/skl_groups.divergences.KNNDivergenceEstimator.html#skl_groups.divergences.KNNDivergenceEstimator" title="skl_groups.divergences.KNNDivergenceEstimator"><tt class="xref py py-class docutils literal"><span class="pre">divergences.KNNDivergenceEstimator</span></tt></a> can get computationally expensive
if you have a lot of points in your sets or if you have a lot of sets.
If your source data is low-dimensional (no more than 5),
one way around that problem is to use <a class="reference internal" href="skl_groups/skl_groups.summaries.L2DensityTransformer.html#skl_groups.summaries.L2DensityTransformer" title="skl_groups.summaries.L2DensityTransformer"><tt class="xref py py-class docutils literal"><span class="pre">summaries.L2DensityTransformer</span></tt></a>,
which transforms bags of features into vectors whose inner product
is an estimate of the <span class="math">\(L_2\)</span> distance between the underlying densities.</p>
<p>Thus you can use its output like a regular feature matrix,
which will be roughly equivalent to directly using the output of
<tt class="xref py py-class docutils literal"><span class="pre">divergences.KNNDivergenceEstimator(div_funcs=['l2'])</span></tt> as a kernel matrix.
You could also pass it through, say, an RBF kernel.</p>
<p>The way the math here works, your input features all need to be in [0, 1];
<a class="reference internal" href="skl_groups/skl_groups.preprocessing.BagMinMaxScaler.html#skl_groups.preprocessing.BagMinMaxScaler" title="skl_groups.preprocessing.BagMinMaxScaler"><tt class="xref py py-class docutils literal"><span class="pre">preprocessing.BagMinMaxScaler</span></tt></a> can help with that.</p>
<p>For example:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skl_groups.preprocessing</span> <span class="kn">import</span> <span class="n">BagMinMaxScaler</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">skl_groups.summaries</span> <span class="kn">import</span> <span class="n">L2DensityTransformer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
<span class="go">    (&#39;scale&#39;, BagMinMaxScaler((0, 1))),</span>
<span class="go">    (&#39;l2&#39;, L2DensityTransformer(smoothness=5)),</span>
<span class="go">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l2ized</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">feats</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l2ized</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(7, 26)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">SVC</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">l2ized</span><span class="p">[:</span><span class="mi">6</span><span class="p">],</span> <span class="n">labels</span><span class="p">[:</span><span class="mi">6</span><span class="p">])</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">l2ized</span><span class="p">[</span><span class="mi">6</span><span class="p">:])</span>
<span class="go">array([False], dtype=bool)</span>
</pre></div>
</div>
<p>Note that the intermediate dimensionality is 26.
We can again plot a two-dimensional approximation:</p>
<p>(<a class="reference external" href=".//tutorial-7.py">Source code</a>, <a class="reference external" href=".//tutorial-7.png">png</a>, <a class="reference external" href=".//tutorial-7.hires.png">hires.png</a>, <a class="reference external" href=".//tutorial-7.pdf">pdf</a>)</p>
<div class="figure">
<img alt="_images/tutorial-7.png" src="_images/tutorial-7.png" />
</div>
</div>
</div>


          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="reference.html" class="btn btn-neutral float-right" title="API reference"/>Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="installation.html" class="btn btn-neutral" title="Installation"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2014, Dougal J. Sutherland.
    </p>
  </div>

  <a href="https://github.com/snide/sphinx_rtd_theme">Sphinx theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>
</footer>
        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.1.0-dev',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>